# ml/backtest_stacked.py
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
import joblib
import os

# === –ü—É—Ç–∏ ===
MODEL_PATH = "./models/btc_long_stacked_v2_model_15m.pkl"
LSTM_MODEL_PATH = "./models/lstm_model_v2_15m.keras"
DATA_15M_PATH = "./data/processed/btc_usdt_15m.parquet"
DATA_1H_PATH = "./data/processed/btc_usdt_1h.parquet"
DATA_4H_PATH = "./data/processed/btc_usdt_4h.parquet"
LOG_FILE = "./logs/backtest_stacked_log.csv"

# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–∏–µ–º!) ===
SEQUENCE_LENGTH = 90      # –ò–∑ stacked_model_v2.py
HOLD_CANDLES = 4          # 4 —Å–≤–µ—á–∏ √ó 15m = 60 –º–∏–Ω—É—Ç
COMMISSION = 0.0008        # 0.08% (Binance)
INITIAL_CAPITAL = 1000.0   # $1000

print("üîç –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µÃÅ—Å—Ç–∞ —Å—Ç–µ–∫–∏–Ω–≥-–º–æ–¥–µ–ª–∏ (15m) —Å –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º...")

# === 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ===
for path, name in [
    (DATA_15M_PATH, "15m"),
    (DATA_1H_PATH, "1h"),
    (DATA_4H_PATH, "4h")
]:
    if not os.path.exists(path):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")

df_15m = pd.read_parquet(DATA_15M_PATH)
df_1h = pd.read_parquet(DATA_1H_PATH)
df_4h = pd.read_parquet(DATA_4H_PATH)

df_15m = df_15m.sort_values("timestamp").reset_index(drop=True)
df_1h = df_1h.sort_values("timestamp").reset_index(drop=True)
df_4h = df_4h.sort_values("timestamp").reset_index(drop=True)

print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_15m)} —Å–≤–µ—á–µ–π (15m)")
print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_1h)} —Å–≤–µ—á–µ–π (1h)")
print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_4h)} —Å–≤–µ—á–µ–π (4h)")

# === 2. –§–∏—á–∏ –¥–ª—è 15m ===
def add_features(df):
    df = df.copy()
    df['sma_20'] = df['close'].rolling(20).mean()
    df['sma_50'] = df['close'].rolling(50).mean()
    df['volatility'] = df['high'] - df['low']
    df['momentum'] = df['close'] - df['close'].shift(5)
    df['volume_ma'] = df['volume'].rolling(10).mean()
    df['volume_ratio'] = df['volume'] / (df['volume_ma'] + 1e-8)
    return df

df_15m = add_features(df_15m)
df_1h = add_features(df_1h)
df_4h = add_features(df_4h)

# === 3. –î–æ–±–∞–≤–ª—è–µ–º –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã–µ —Ñ–∏—á–∏ ===
# –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º 1h –∏ 4h –∫ 15m –ø–æ –≤—Ä–µ–º–µ–Ω–∏
df_15m['trend_1h'] = df_15m['timestamp'].map(
    df_1h.set_index('timestamp')['close'] > df_1h.set_index('timestamp')['sma_50']
)
df_15m['volume_spike_4h'] = df_15m['timestamp'].map(
    df_4h.set_index('timestamp')['volume'] > df_4h.set_index('timestamp')['volume'].rolling(10).mean() * 1.5
)

# ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NaN
df_15m['trend_1h'] = pd.to_numeric(df_15m['trend_1h'], errors='coerce').ffill().bfill().astype(int)
df_15m['volume_spike_4h'] = pd.to_numeric(df_15m['volume_spike_4h'], errors='coerce').ffill().bfill().astype(int)

# === 4. –§–∏—á–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ ===
features = [
    'close', 'volume', 'sma_20', 'sma_50', 'volatility',
    'momentum', 'volume_ratio', 'trend_1h', 'volume_spike_4h'
]

# === 5. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ ===
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"–ú–µ—Ç–∞-–º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {MODEL_PATH}")

if not os.path.exists(LSTM_MODEL_PATH):
    raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å LSTM –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {LSTM_MODEL_PATH}")

try:
    stacked = joblib.load(MODEL_PATH)
    print(f"‚úÖ –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {MODEL_PATH}")
except Exception as e:
    raise RuntimeError(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏: {e}")

try:
    lstm_model = load_model(LSTM_MODEL_PATH)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å LSTM –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {LSTM_MODEL_PATH}")
except Exception as e:
    raise RuntimeError(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LSTM: {e}")

# === 6. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ç–∫—Ç–µÃÅ—Å—Ç–∞ ===
trades = []
capital = INITIAL_CAPITAL
equity_curve = [capital]

if len(df_15m) < SEQUENCE_LENGTH:
    raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(df_15m)} < {SEQUENCE_LENGTH}")

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
X_seq, X_flat = [], []
for i in range(SEQUENCE_LENGTH, len(df_15m)):
    X_seq.append(df_15m[features].iloc[i - SEQUENCE_LENGTH:i].values)
    X_flat.append(df_15m[features].iloc[i].values)

X_seq = np.array(X_seq)
X_flat = np.array(X_flat)

print(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(X_seq)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –±—ç–∫—Ç–µÃÅ—Å—Ç–∞")

# === 7. –ë—ç–∫—Ç–µÃÅ—Å—Ç (—Å –∑–∞–ø—Ä–µ—Ç–æ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è —Å–¥–µ–ª–æ–∫) ===
last_exit_idx = -1  # –ò–Ω–¥–µ–∫—Å, –¥–æ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ–ª—å–∑—è –æ—Ç–∫—Ä—ã–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Å–¥–µ–ª–∫–∏

for i in range(len(X_seq)):
    try:
        # –¢–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å –≤ df_15m
        current_idx = SEQUENCE_LENGTH + i

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–∞—è —Å–¥–µ–ª–∫–∞
        if current_idx < last_exit_idx:
            equity_curve.append(capital)
            continue

        # –ü—Ä–æ–≥–Ω–æ–∑ LSTM
        lstm_proba = lstm_model.predict(X_seq[i:i+1], verbose=0).flatten()[0]

        # –ü—Ä–æ–≥–Ω–æ–∑ XGBoost ‚Äî —Å –∏–º–µ–Ω–∞–º–∏ —Ñ–∏—á–µ–π (—á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)
        X_sample = pd.DataFrame([X_flat[i]], columns=stacked['features'])
        xgb_proba = stacked['xgb_model'].predict_proba(X_sample)[0, 1]

        # –°—Ç–µ–∫–∏–Ω–≥: LightGBM –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        stacked_input = np.array([[lstm_proba, xgb_proba]])
        stacked_proba = stacked['meta_model'].predict_proba(stacked_input)[0, 1]

        # ‚úÖ –°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª + —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ —Ç—Ä–µ–Ω–¥—É –∏ –æ–±—ä—ë–º—É
        if (
            stacked_proba > 0.8 and
            df_15m.iloc[current_idx]['trend_1h'] == 1 and
            df_15m.iloc[current_idx]['volume_spike_4h'] == 1
        ):
            entry_idx = current_idx
            exit_idx = entry_idx + HOLD_CANDLES

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—Ü
            if exit_idx >= len(df_15m):
                equity_curve.append(capital)
                continue

            entry_price = df_15m.iloc[entry_idx]["close"]
            exit_price = df_15m.iloc[exit_idx]["close"]

            pnl_gross = (exit_price - entry_price) / entry_price
            pnl_net = pnl_gross - COMMISSION
            capital *= (1 + pnl_net)

            trades.append({
                "entry_time": df_15m.iloc[entry_idx]["timestamp"],
                "exit_time": df_15m.iloc[exit_idx]["timestamp"],
                "entry_price": entry_price,
                "exit_price": exit_price,
                "pnl_net": pnl_net
            })

            # ‚úÖ –ó–∞–ø—Ä–µ—â–∞–µ–º –Ω–æ–≤—ã–µ —Å–¥–µ–ª–∫–∏ –¥–æ –≤—ã—Ö–æ–¥–∞
            last_exit_idx = exit_idx

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ {i}: {e}")
        equity_curve.append(capital)
        continue

    equity_curve.append(capital)

# === 8. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
if trades:
    df_trades = pd.DataFrame(trades)
    win_rate = (df_trades["pnl_net"] > 0).mean()
    total_return = (capital / INITIAL_CAPITAL - 1) * 100
    avg_pnl = df_trades["pnl_net"].mean()
    max_drawdown = df_trades["pnl_net"].min()

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µÃÅ—Å—Ç–∞ (15m + 1h + 4h):")
    print(f"  –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {len(df_trades)}")
    print(f"  Win Rate: {win_rate:.1%}")
    print(f"  –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å (—á–∏—Å—Ç–∞—è): {avg_pnl:+.2%}")
    print(f"  –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {total_return:+.2f}%")
    print(f"  –ö–æ–Ω–µ—á–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${capital:.2f}")
    print(f"  –ú–∞–∫—Å. –ø—Ä–æ—Å–∞–¥–∫–∞: {max_drawdown:+.2%}")
else:
    print("‚ùå –ù–µ—Ç —Å–¥–µ–ª–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

# === 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–∞ ===
os.makedirs("./logs", exist_ok=True)
if trades:
    df_trades.to_csv(LOG_FILE, index=False)
    print(f"‚úÖ –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {LOG_FILE}")
else:
    print("‚ö†Ô∏è –ù–µ—Ç —Å–¥–µ–ª–æ–∫ ‚Äî –ª–æ–≥ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω")

print("‚úÖ –ë—ç–∫—Ç–µÃÅ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω")