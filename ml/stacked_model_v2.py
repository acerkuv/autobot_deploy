# ml/stacked_model_v2.py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import joblib
import os

# === –ü—É—Ç–∏ ===
DATA_15M_PATH = "./data/processed/btc_usdt_15m.parquet"
DATA_1H_PATH = "./data/processed/btc_usdt_1h.parquet"
MODEL_SAVE_PATH = "./models/btc_long_stacked_v2_model_15m.pkl"
LSTM_MODEL_PATH = "./models/lstm_model_v2_15m.keras"
LOG_FILE = "./logs/model_training_log.csv"

# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ===
SEQUENCE_LENGTH = 90      # 60 —Å–≤–µ—á–µ–π √ó 15m = 15 —á–∞—Å–æ–≤
MAX_HISTORY = 20000       # –ú–∞–∫—Å–∏–º—É–º 20k —Å–≤–µ—á–µ–π
HOLD_CANDLES = 4          # –î–µ—Ä–∂–∏–º 4 —Å–≤–µ—á–∏ = 60 –º–∏–Ω—É—Ç (1 —á–∞—Å)
TEST_SIZE = 72            # ~12 —á–∞—Å–æ–≤ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é (48 √ó 15m)
COMMISSION = 0.0008       # 0.08% –∫–æ–º–∏—Å—Å–∏—è

print("üîç –û–±—É—á–µ–Ω–∏–µ —Å—Ç–µ–∫–∏–Ω–≥-–º–æ–¥–µ–ª–∏: LSTM + XGBoost ‚Üí LightGBM (meta) –Ω–∞ 15m")

# === 1. –ó–∞–≥—Ä—É–∂–∞–µ–º 15m –¥–∞–Ω–Ω—ã–µ ===
if not os.path.exists(DATA_15M_PATH):
    raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {DATA_15M_PATH}")

df = pd.read_parquet(DATA_15M_PATH)
df = df.sort_values("timestamp").reset_index(drop=True)
print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π (15m)")

# –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
if len(df) > MAX_HISTORY:
    df = df.iloc[-MAX_HISTORY:].copy()
    print(f"üìâ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {MAX_HISTORY} —Å–≤–µ—á–µ–π")

# === 2. –ó–∞–≥—Ä—É–∂–∞–µ–º 1h –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ç—Ä–µ–Ω–¥—É ===
if os.path.exists(DATA_1H_PATH):
    df_1h = pd.read_parquet(DATA_1H_PATH)
    df_1h = df_1h.sort_values("timestamp").reset_index(drop=True)
    # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é 1h —Å–≤–µ—á—É –∫ 15m
    last_1h_close = df_1h['close'].iloc[-1]
    df['trend_1h'] = (df['close'] > df['close'].rolling(50).mean()).astype(int)
    print("‚úÖ –î–∞–Ω–Ω—ã–µ 1h –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –¥–æ–±–∞–≤–ª–µ–Ω —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç—Ä–µ–Ω–¥—É")
else:
    print("‚ö†Ô∏è –§–∞–π–ª 1h –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞.")
    df['trend_1h'] = 1  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–∑—Ä–µ—à–∞–µ–º –≤—Å–µ —Å–¥–µ–ª–∫–∏

# === 3. –§–∏—á–∏ ===
def add_features(df):
    df = df.copy()
    df['sma_20'] = df['close'].rolling(20).mean()
    df['sma_50'] = df['close'].rolling(50).mean()
    df['volatility'] = df['high'] - df['low']
    df['momentum'] = df['close'] - df['close'].shift(5)
    df['volume_ma'] = df['volume'].rolling(10).mean()
    df['volume_ratio'] = df['volume'] / (df['volume_ma'] + 1e-8)
    return df

df = add_features(df)

# –§–∏—á–∏ –¥–ª—è XGBoost
features = [
    'close', 'volume', 'sma_20', 'sma_50', 'volatility',
    'momentum', 'volume_ratio', 'trend_1h'
]

# === 4. –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: –∑–∞–∫—Ä—ã—Ç–∏–µ –≤—ã—à–µ SMA-20 —á–µ—Ä–µ–∑ 4 —Å–≤–µ—á–∏ ===
df['future_close'] = df['close'].shift(-HOLD_CANDLES)
df['target'] = (df['future_close'] > df['sma_20']).astype(int)

# –£–¥–∞–ª—è–µ–º NaN
df.dropna(subset=features + ['target'], inplace=True)
df = df.reset_index(drop=True)

# === 5. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LSTM ===
def create_sequences(data, seq_len, features, target_col):
    X, y = [], []
    for i in range(seq_len, len(data)):
        X.append(data[features].iloc[i-seq_len:i].values)
        y.append(data[target_col].iloc[i])
    return np.array(X), np.array(y)

X_seq, y_seq = create_sequences(df, SEQUENCE_LENGTH, features, 'target')
X_flat = df[features].values[SEQUENCE_LENGTH:]
y_flat = df['target'].values[SEQUENCE_LENGTH:]

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
split_idx = len(X_seq) - TEST_SIZE
X_train_seq, X_val_seq = X_seq[:split_idx], X_seq[split_idx:]
X_train_flat, X_val_flat = X_flat[:split_idx], X_flat[split_idx:]
y_train, y_val = y_seq[:split_idx], y_seq[split_idx:]

print(f"üìä –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {len(X_train_seq)} | –í–∞–ª–∏–¥–∞—Ü–∏—è: {len(X_val_seq)}")

# === 6. LSTM –º–æ–¥–µ–ª—å (1-–π —É—Ä–æ–≤–µ–Ω—å) ===
def create_lstm_model(input_shape):
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(50, return_sequences=False),
        Dropout(0.2),
        Dense(25, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

lstm_model = create_lstm_model((SEQUENCE_LENGTH, len(features)))
print("üß† –û–±—É—á–µ–Ω–∏–µ LSTM...")
lstm_model.fit(
    X_train_seq, y_train,
    epochs=10,
    batch_size=32,
    validation_data=(X_val_seq, y_val),
    verbose=1
)

# –ü—Ä–æ–≥–Ω–æ–∑—ã LSTM
lstm_train_proba = lstm_model.predict(X_train_seq).flatten()
lstm_val_proba = lstm_model.predict(X_val_seq).flatten()

# === 7. XGBoost –º–æ–¥–µ–ª—å (1-–π —É—Ä–æ–≤–µ–Ω—å) ===
xgb_model = XGBClassifier(n_estimators=100, random_state=42)
xgb_model.fit(X_train_flat, y_train)

# –ü—Ä–æ–≥–Ω–æ–∑—ã XGBoost
xgb_train_proba = xgb_model.predict_proba(X_train_flat)[:, 1]
xgb_val_proba = xgb_model.predict_proba(X_val_flat)[:, 1]

# === 8. –°—Ç–µ–∫–∏–Ω–≥: LightGBM –∫–∞–∫ –º–µ—Ç–∞-–º–æ–¥–µ–ª—å (2-–π —É—Ä–æ–≤–µ–Ω—å) ===
X_train_stack = np.column_stack([lstm_train_proba, xgb_train_proba])
X_val_stack = np.column_stack([lstm_val_proba, xgb_val_proba])

# –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å ‚Äî LightGBM
meta_model = LGBMClassifier(
    n_estimators=50,
    random_state=42,
    objective='binary',
    metric='binary_logloss'
)
meta_model.fit(X_train_stack, y_train)

# –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
y_proba_stacked = meta_model.predict_proba(X_val_stack)[:, 1]
y_pred_stacked = (y_proba_stacked > 0.6).astype(int)  # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥

# === 9. –ú–µ—Ç—Ä–∏–∫–∏ ===
acc = accuracy_score(y_val, y_pred_stacked)
prec = precision_score(y_val, y_pred_stacked, zero_division=0)
rec = recall_score(y_val, y_pred_stacked, zero_division=0)
auc = roc_auc_score(y_val, y_proba_stacked)

print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Å—Ç–µ–∫–∏–Ω–≥–∞ (15m):")
print(f"  Accuracy: {acc:.3f}")
print(f"  Precision: {prec:.3f}")
print(f"  Recall: {rec:.3f}")
print(f"  AUC: {auc:.3f}")

# === 10. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ===
os.makedirs("./models", exist_ok=True)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞-–º–æ–¥–µ–ª—å –∏ –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
joblib.dump({
    'xgb_model': xgb_model,
    'meta_model': meta_model,
    'sequence_length': SEQUENCE_LENGTH,
    'features': features
}, MODEL_SAVE_PATH)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º LSTM
lstm_model.save(LSTM_MODEL_PATH)

print("‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å—Ç–µ–∫–∏–Ω–≥-–º–æ–¥–µ–ª—å (15m) —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

# === 11. –õ–æ–≥ –æ–±—É—á–µ–Ω–∏—è ===
os.makedirs("./logs", exist_ok=True)
log_entry = {
    "timestamp": pd.Timestamp.now().isoformat(),
    "model": "stacked_lstm_xgb_lgbm_15m",
    "accuracy": acc,
    "precision": prec,
    "recall": rec,
    "auc": auc,
    "status": "valid" if auc > 0.65 else "invalid"
}
log_df = pd.DataFrame([log_entry])
log_df.to_csv(LOG_FILE, mode='a', header=not os.path.exists(LOG_FILE), index=False)
print("‚úÖ –õ–æ–≥ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω")