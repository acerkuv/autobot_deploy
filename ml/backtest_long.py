# ml/backtest_long.py
import pandas as pd
import numpy as np
from lightgbm import LGBMClassifier
from sklearn.metrics import precision_score, recall_score, roc_auc_score
import joblib
import os

# === –ü—É—Ç–∏ ===
PROJECT_ROOT = "."
DATA_PATH = os.path.join(PROJECT_ROOT, "data", "processed", "btc_usdt_3m.parquet")
LOGS_DIR = os.path.join(PROJECT_ROOT, "logs")
LOG_FILE = os.path.join(LOGS_DIR, "backtest_log.csv")

# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ===
WINDOW_TRAIN_HOURS = 30    # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ 30 —á–∞—Å–∞—Ö
VALIDATION_HOURS = 12      # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏—Ö 12 —á–∞—Å–∞—Ö
STEP_HOURS = 3             # –®–∞–≥: +3 —á–∞—Å–∞
HOLD_CANDLES = 12          # –î–µ—Ä–∂–∏–º —Å–¥–µ–ª–∫—É 12 —Å–≤–µ—á–µ–π (36 –º–∏–Ω—É—Ç)
MIN_DATA_FOR_TRAIN = 600   # –ú–∏–Ω–∏–º—É–º 600 —Å–≤–µ—á–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
CONFIDENCE_THRESHOLD = 0.85 # –í—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
COMMISSION = 0.0008         # –ö–æ–º–∏—Å—Å–∏—è Binance: 0.04% + 0.04%
INITIAL_CAPITAL = 1000.0    # –ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª

print("üîç –ó–∞–ø—É—Å–∫ –î–õ–ò–ù–ù–û–ì–û –±—ç–∫—Ç–µÃÅ—Å—Ç–∞ —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π...")

# === 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ===
if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {DATA_PATH}")

df = pd.read_parquet(DATA_PATH)
df = df.sort_values("timestamp").reset_index(drop=True)
print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π (3m)")

# === 2. –§–∏—á–∏ ===
def add_features(df):
    df = df.copy()
    df['sma_20'] = df['close'].rolling(20).mean()
    df['sma_50'] = df['close'].rolling(50).mean()
    df['volatility'] = df['high'] - df['low']
    df['momentum'] = df['close'] - df['close'].shift(5)
    df['volume_ma'] = df['volume'].rolling(10).mean()
    df['volume_ratio'] = df['volume'] / (df['volume_ma'] + 1e-8)
    return df

df = add_features(df)

# === –ó–∞–≥—Ä—É–∂–∞–µ–º 1h –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ç—Ä–µ–Ω–¥—É ===
DATA_1H_PATH = os.path.join(PROJECT_ROOT, "data", "processed", "btc_usdt_1h.parquet")
if os.path.exists(DATA_1H_PATH):
    df_1h = pd.read_parquet(DATA_1H_PATH)
    df_1h = df_1h.sort_values("timestamp").reset_index(drop=True)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_1h)} —Å–≤–µ—á–µ–π (1h)")

    # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Ç—Ä–µ–Ω–¥ 1h –∫ 3m
    df_1h['hour'] = pd.to_datetime(df_1h['timestamp'], unit='ms').dt.floor('H')
    df['hour'] = pd.to_datetime(df['timestamp'], unit='ms').dt.floor('H')
    df = df.merge(df_1h[['hour', 'close']], on='hour', suffixes=('', '_1h'), how='left')
    df['trend_1h'] = (df['close'] > df['close_1h'].rolling(20).mean()).astype(int)
    df['trend_1h'] = df['trend_1h'].fillna(1).astype(int)  # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî —Å—á–∏—Ç–∞–µ–º —Ç—Ä–µ–Ω–¥ –≤–æ—Å—Ö–æ–¥—è—â–∏–º
else:
    print("‚ö†Ô∏è –§–∞–π–ª 1h –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ç—Ä–µ–Ω–¥—É.")
    df['trend_1h'] = 1  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–∑—Ä–µ—à–∞–µ–º –≤—Å–µ —Å–¥–µ–ª–∫–∏

# –§–∏—á–∏ ‚Äî –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¢–û–ß–ù–û —Ç–∞–∫–∏–º–∏ –∂–µ, –∫–∞–∫ –≤ train.py
features = [
    'close', 'volume', 'sma_20', 'sma_50', 'volatility',
    'momentum', 'volume_ratio'
]

# === 3. –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: +0.2% –∑–∞ 12 —Å–≤–µ—á–µ–π (36 –º–∏–Ω) ===
df['future_close'] = df['close'].shift(-HOLD_CANDLES)
df['target'] = (df['future_close'] > df['close'] * 1.002).astype(int)

# –£–¥–∞–ª—è–µ–º NaN
df.dropna(subset=features + ['target', 'trend_1h'], inplace=True)
df = df.reset_index(drop=True)

print(f"üìä –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(df)} —Å–≤–µ—á–µ–π")

# === 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –±—ç–∫—Ç–µÃÅ—Å—Ç–∞ ===
trades = []
signals = []
log_entries = []

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π –∑–∞ —á–∞—Å: 20 (—Ç.–∫. 3m ‚Üí 20 —Å–≤–µ—á–µ–π –≤ —á–∞—Å)
CANDLES_PER_HOUR = 20
step_candles = STEP_HOURS * CANDLES_PER_HOUR
window_candles = WINDOW_TRAIN_HOURS * CANDLES_PER_HOUR
val_candles = VALIDATION_HOURS * CANDLES_PER_HOUR

# –ù–∞—á–∏–Ω–∞–µ–º —Å –º–æ–º–µ–Ω—Ç–∞, –∫–æ–≥–¥–∞ –º–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å—Å—è
current_idx = window_candles

# –°—á—ë—Ç—á–∏–∫–∏
total_signals = 0
valid_windows = 0
equity_curve = [INITIAL_CAPITAL]  # –ö—Ä–∏–≤–∞—è –∫–∞–ø–∏—Ç–∞–ª–∞

while current_idx < len(df) - val_candles:
    try:
        # –û–±—É—á–∞—é—â–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω: 30 —á–∞—Å–æ–≤ –¥–æ current_idx
        train_start_idx = current_idx - window_candles
        X_train = df.iloc[train_start_idx:current_idx][features]
        y_train = df.iloc[train_start_idx:current_idx]['target']

        if len(X_train) < MIN_DATA_FOR_TRAIN:
            print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(X_train)}")
            current_idx += step_candles
            continue

        # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: —Å–ª–µ–¥—É—é—â–∏–µ 12 —á–∞—Å–æ–≤
        val_end_idx = min(current_idx + val_candles, len(df))
        X_val = df.iloc[current_idx:val_end_idx][features]
        y_val = df.iloc[current_idx:val_end_idx]['target']

        if len(X_val) == 0:
            current_idx += step_candles
            continue

        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –µ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏
        if y_train.sum() == 0:
            print("‚ö†Ô∏è –ù–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–æ–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏")
            current_idx += step_candles
            continue

        # –í–µ—Å –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        pos_weight = len(y_train) / y_train.sum()

        # === –û–¥–Ω–∞ –º–æ–¥–µ–ª—å: LightGBM (—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è) ===
        model = LGBMClassifier(
            n_estimators=100,
            random_state=42,
            scale_pos_weight=pos_weight,
            min_child_samples=20,
            objective='binary',
            metric='binary_logloss'
        )
        model.fit(X_train, y_train)

        # –ü—Ä–æ–≥–Ω–æ–∑
        y_proba = model.predict_proba(X_val)[:, 1]
        y_pred = (y_proba > CONFIDENCE_THRESHOLD).astype(int)

        # üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        print(f"üîπ –í–∞–ª–∏–¥–∞—Ü–∏—è: {df.iloc[current_idx]['timestamp']} ‚Üí {df.iloc[val_end_idx-1]['timestamp']}")
        print(f"üîπ X_train shape: {X_train.shape}, X_val shape: {X_val.shape}")
        print(f"üîπ y_train sum: {y_train.sum()}, y_val sum: {y_val.sum()}")

        # üìä –í–∞–ª–∏–¥–∞—Ü–∏—è: –º–µ—Ç—Ä–∏–∫–∏
        if y_val.sum() > 0:
            prec = precision_score(y_val, y_pred, zero_division=0)
            rec = recall_score(y_val, y_pred, zero_division=0)
            auc = roc_auc_score(y_val, y_proba)
            print(f"üìä –í–∞–ª–∏–¥–∞—Ü–∏—è: Prec={prec:.3f}, Rec={rec:.3f}, AUC={auc:.3f}")
        else:
            print("‚ö†Ô∏è –ù–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–æ–∫ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –º–µ—Ç—Ä–∏–∫")

        print(f"üîπ –°–∏–≥–Ω–∞–ª–æ–≤ (confidence > {CONFIDENCE_THRESHOLD}): {y_pred.sum()} –∏–∑ {len(y_pred)}")
        total_signals += y_pred.sum()

        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Å–¥–µ–ª–∫–∏
        capital = equity_curve[-1]
        for i, signal in enumerate(y_pred):
            if signal == 1:
                entry_idx = current_idx + i
                # ‚úÖ –§–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç—Ä–µ–Ω–¥ 1h –≤–æ—Å—Ö–æ–¥—è—â–∏–π
                if df.iloc[entry_idx]['trend_1h'] == 0:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ —Ç—Ä–µ–Ω–¥ –Ω–µ –≤–æ—Å—Ö–æ–¥—è—â–∏–π

                entry_price = df.iloc[entry_idx]["close"]
                exit_idx = min(entry_idx + HOLD_CANDLES, len(df) - 1)
                exit_price = df.iloc[exit_idx]["close"]
                pnl_gross = (exit_price - entry_price) / entry_price
                pnl_net = pnl_gross - COMMISSION  # –£—á—ë—Ç –∫–æ–º–∏—Å—Å–∏–∏
                capital *= (1 + pnl_net)

                trades.append({
                    "entry_time": df.iloc[entry_idx]["timestamp"],
                    "exit_time": df.iloc[exit_idx]["timestamp"],
                    "entry_price": entry_price,
                    "exit_price": exit_price,
                    "pnl_gross": pnl_gross,
                    "pnl_net": pnl_net
                })

        equity_curve.append(capital)

        # –õ–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        log_entries.append({
            "train_start": df.iloc[train_start_idx]["timestamp"],
            "train_end": df.iloc[current_idx - 1]["timestamp"],
            "val_start": df.iloc[current_idx]["timestamp"],
            "val_end": df.iloc[val_end_idx - 1]["timestamp"],
            "train_size": len(X_train),
            "val_size": len(X_val),
            "pos_weight": pos_weight,
            "signals": y_pred.sum(),
            "capital": capital
        })

        valid_windows += 1
        current_idx += step_candles

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ {current_idx}: {e}")
        current_idx += step_candles
        continue

# === 5. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
print(f"\nüìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –æ–∫–æ–Ω: {valid_windows}, –≤—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {total_signals}")

if trades:
    df_trades = pd.DataFrame(trades)
    win_rate = (df_trades["pnl_net"] > 0).mean()
    total_return = (equity_curve[-1] / INITIAL_CAPITAL - 1) * 100
    avg_pnl = df_trades["pnl_net"].mean()
    max_drawdown = df_trades["pnl_net"].min()

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –î–õ–ò–ù–ù–û–ì–û –±—ç–∫—Ç–µÃÅ—Å—Ç–∞:")
    print(f"  –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {len(df_trades)}")
    print(f"  Win Rate: {win_rate:.1%}")
    print(f"  –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å (—á–∏—Å—Ç–∞—è): {avg_pnl:+.2%}")
    print(f"  –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {total_return:+.2f}%")
    print(f"  –ö–æ–Ω–µ—á–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${equity_curve[-1]:.2f}")
    print(f"  –ú–∞–∫—Å. –ø—Ä–æ—Å–∞–¥–∫–∞ (–ø–æ —Å–¥–µ–ª–∫–∞–º): {max_drawdown:+.2%}")
else:
    print("‚ùå –ù–µ—Ç —Å–¥–µ–ª–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

# === 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–∞ ===
os.makedirs(LOGS_DIR, exist_ok=True)
if log_entries:
    log_df = pd.DataFrame(log_entries)
    log_df.to_csv(LOG_FILE, index=False)
    print(f"‚úÖ –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {LOG_FILE}")
else:
    print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–∞")

print("‚úÖ –î–ª–∏–Ω–Ω—ã–π –±—ç–∫—Ç–µÃÅ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω")