import pandas as pd
import requests
import os
import time
from datetime import datetime, timedelta
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
SYMBOL = "BTC-USDT"
TIMEFRAME = "3m"
DEEP_DAYS = 2
LIMIT_PER_REQUEST = 100
REQUEST_DELAY = 0.5  # –£–≤–µ–ª–∏—á–∏–ª–∏ –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
MAX_REQUESTS = 50

def fetch_candles(symbol, timeframe, start_ts, end_ts, max_requests=MAX_REQUESTS):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–≤–µ—á–∏ –∏—Å–ø–æ–ª—å–∑—É—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏"""
    candles = []
    request_count = 0
    last_ts = end_ts
    
    while request_count < max_requests:
        request_count += 1
        url = f"https://www.okx.com/api/v5/market/history-candles?instId={symbol}&bar={timeframe}&before={last_ts}&limit={LIMIT_PER_REQUEST}"
        
        try:
            response = requests.get(url, timeout=15)
            if response.status_code != 200:
                logger.warning(f"HTTP error {response.status_code}")
                time.sleep(2)
                continue
                
            data = response.json().get("data", [])
            
            if not data:
                logger.info("No more data available")
                break
                
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–≤–µ—á–∏
            new_candles = []
            for candle in data:
                try:
                    ts = int(candle[0])
                    if ts < start_ts:
                        continue
                        
                    new_candles.append({
                        "timestamp_ms": ts,
                        "timestamp": datetime.utcfromtimestamp(ts / 1000),
                        "open": float(candle[1]),
                        "high": float(candle[2]),
                        "low": float(candle[3]),
                        "close": float(candle[4]),
                        "volume_btc": float(candle[5]),
                        "volume_usdt": float(candle[6]),
                    })
                except (IndexError, ValueError) as e:
                    logger.warning(f"Invalid candle format: {candle} - {str(e)}")
            
            if not new_candles:
                logger.info("No new candles in response")
                break
                
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–≤–µ—á–∏
            candles.extend(new_candles)
            
            # –ü–æ–ª—É—á–∞–µ–º timestamp —Å–∞–º–æ–π —Å—Ç–∞—Ä–æ–π —Å–≤–µ—á–∏ –≤ –æ—Ç–≤–µ—Ç–µ
            oldest_ts = min([c["timestamp_ms"] for c in new_candles])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            if oldest_ts >= last_ts:
                logger.warning("Pagination error: timestamp not decreasing")
                # –ü—ã—Ç–∞–µ–º—Å—è —Å–¥–≤–∏–Ω—É—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–º–µ—Ä –ª–∏–º–∏—Ç–∞
                last_ts = oldest_ts - (180000 * LIMIT_PER_REQUEST)
            else:
                last_ts = oldest_ts
                
            logger.info(f"Request #{request_count}: got {len(new_candles)} candles, oldest: {datetime.utcfromtimestamp(oldest_ts/1000).strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            logger.error(f"Request failed: {str(e)}")
            time.sleep(3)
            
        time.sleep(REQUEST_DELAY)
    
    return candles

def main():
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
    end_time = datetime.utcnow() - timedelta(minutes=3)  # –ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Å–≤–µ—á–∞
    start_time = end_time - timedelta(days=DEEP_DAYS)
    
    logger.info(f"üîç Loading {DEEP_DAYS} days of data")
    logger.info(f"üîç Start: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"üîç End: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ timestamp –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
    end_ts = int(end_time.timestamp() * 1000)
    start_ts = int(start_time.timestamp() * 1000)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    candles = fetch_candles(SYMBOL, TIMEFRAME, start_ts, end_ts)
    
    if not candles:
        logger.error("‚ùå No candles loaded")
        return
        
    # –°–æ–∑–¥–∞–µ–º DataFrame
    df = pd.DataFrame(candles)
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    initial_count = len(df)
    df = df.drop_duplicates("timestamp_ms")
    if initial_count != len(df):
        logger.warning(f"Removed {initial_count - len(df)} duplicates")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    df = df.sort_values("timestamp").reset_index(drop=True)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É
    df = df[(df["timestamp"] >= start_time) & (df["timestamp"] <= end_time)]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    os.makedirs("data/processed", exist_ok=True)
    filepath = f"data/processed/{SYMBOL.lower().replace('-', '_')}_{TIMEFRAME}.parquet"
    df.to_parquet(filepath, index=False)
    
    # –û—Ç—á–µ—Ç
    logger.info(f"‚úÖ Successfully saved {len(df)} candles")
    logger.info(f"üìÖ First candle: {df['timestamp'].min().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"üìÖ Last candle: {df['timestamp'].max().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"üíæ File: {filepath}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
    expected_candles = DEEP_DAYS * 24 * 60 // 3
    if len(df) < expected_candles:
        logger.warning(f"‚ö†Ô∏è Warning: loaded {len(df)} of {expected_candles} expected candles")
    else:
        logger.info(f"üìä Data completeness: 100% ({len(df)}/{expected_candles} candles)")
    
    # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–≤–µ—á–µ–π
    logger.info("\nLast 5 candles:")
    logger.info(df[["timestamp", "close"]].tail().to_string(index=False))

if __name__ == "__main__":
    main()